{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b34b39-9a0a-4d84-87f2-82aa1f4e2ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.sql.types import StructType, StringType, BinaryType, IntegerType, DoubleType, TimestampType, DateType\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from typing import Union, Optional\n",
    "\n",
    "# --- Credenciais AWS ---\n",
    "accessKeyId = \"\"\n",
    "secretAccessKey = \"\"\n",
    "\n",
    "# --- Sessão Spark ---\n",
    "def create_spark_session() -> SparkSession:\n",
    "    spark = (\n",
    "        SparkSession\n",
    "        .builder\n",
    "        .appName(\"Silver Zone\")\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    \n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "    conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "    conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "    conf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\")\n",
    "    conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    conf.set(\"fs.s3a.fast.upload\", \"true\")\n",
    "    conf.set(\"fs.s3a.bucket.all.committer.magic.enabled\", \"true\")\n",
    "    conf.set(\"fs.s3a.directory.marker.retention\", \"keep\")\n",
    "    conf.set(\"spark.driver.extraClassPath\", \"/usr/local/spark/jars/*\")\n",
    "    conf.set(\"spark.driver.memory\", \"8g\")\n",
    "    conf.set(\"spark.executor.memory\", \"16g\")\n",
    "    conf.set(\"fs.s3a.access.key\", accessKeyId)\n",
    "    conf.set(\"fs.s3a.secret.key\", secretAccessKey)\n",
    "\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c28679a-b3cf-4d05-9d4c-f9e48032c8da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tempview_from_delta(spark, delta_table_path, view_name):\n",
    "    \"\"\"\n",
    "    Cria uma tempView a partir de uma tabela Delta.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - delta_table_path (str): Caminho para a tabela Delta\n",
    "    - view_name (str): Nome da tempView a ser criada\n",
    "    \n",
    "    Retorno:\n",
    "    - None (cria a tempView no SparkSession atual)\n",
    "    \"\"\"\n",
    "   \n",
    "    if spark is None:\n",
    "        raise ValueError(\"Nenhuma SparkSession ativa encontrada\")\n",
    "    \n",
    "    spark.read.format(\"delta\").load(delta_table_path).createOrReplaceTempView(view_name)\n",
    "    \n",
    "    print(f\"TempView '{view_name}' criada com sucesso a partir da tabela Delta em: {delta_table_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97843c8f-61ec-4423-80ce-16fd0523bc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 ms, sys: 0 ns, total: 21.4 ms\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark = create_spark_session()\n",
    "\n",
    "tabelas = [\n",
    "    \"cliente\",\n",
    "    \"profissional\",\n",
    "    \"servico\",\n",
    "    \"agendamento\",\n",
    "    \"pagamento\",\n",
    "    \"horario_profissional\",\n",
    "    \"promocao\",\n",
    "    \"servico_promocao\"\n",
    "]\n",
    "\n",
    "bronze = \"s3a://dev-lab-02-us-east-2-bronze/db_barbearia/\"\n",
    "silver = \"s3a://dev-lab-02-us-east-2-silver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882099b0-c26a-4a12-8617-456f1d16ab8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TempView 'cliente' criada com sucesso a partir da tabela Delta em: s3a://dev-lab-02-us-east-2-bronze/db_barbearia/cliente\n",
      "TempView 'profissional' criada com sucesso a partir da tabela Delta em: s3a://dev-lab-02-us-east-2-bronze/db_barbearia/profissional\n",
      "TempView 'servico' criada com sucesso a partir da tabela Delta em: s3a://dev-lab-02-us-east-2-bronze/db_barbearia/servico\n",
      "TempView 'agendamento' criada com sucesso a partir da tabela Delta em: s3a://dev-lab-02-us-east-2-bronze/db_barbearia/agendamento\n",
      "TempView 'pagamento' criada com sucesso a partir da tabela Delta em: s3a://dev-lab-02-us-east-2-bronze/db_barbearia/pagamento\n",
      "TempView 'horario_profissional' criada com sucesso a partir da tabela Delta em: s3a://dev-lab-02-us-east-2-bronze/db_barbearia/horario_profissional\n",
      "TempView 'promocao' criada com sucesso a partir da tabela Delta em: s3a://dev-lab-02-us-east-2-bronze/db_barbearia/promocao\n",
      "TempView 'servico_promocao' criada com sucesso a partir da tabela Delta em: s3a://dev-lab-02-us-east-2-bronze/db_barbearia/servico_promocao\n"
     ]
    }
   ],
   "source": [
    "for t in tabelas:\n",
    "    create_tempview_from_delta(spark, f\"{bronze}{t}\",t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc74d4bd-3e63-4dfc-947d-752157f36046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|            viewName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|         |         agendamento|       true|\n",
      "|         |             cliente|       true|\n",
      "|         |horario_profissional|       true|\n",
      "|         |           pagamento|       true|\n",
      "|         |        profissional|       true|\n",
      "|         |            promocao|       true|\n",
      "|         |             servico|       true|\n",
      "|         |    servico_promocao|       true|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SHOW VIEWS\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5cb69c-7431-494c-83e0-b12d37ed4fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|     cliente_id|      int|   null|\n",
      "|           nome|   string|   null|\n",
      "|       telefone|   string|   null|\n",
      "|          email|   string|   null|\n",
      "|data_nascimento|     date|   null|\n",
      "|  data_cadastro|timestamp|   null|\n",
      "|    observacoes|   string|   null|\n",
      "|          ativo|  boolean|   null|\n",
      "| ingestion_time|timestamp|   null|\n",
      "|         origem|   string|   null|\n",
      "|  deletion_time|timestamp|   null|\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"describe cliente\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c336c1d-c891-4d57-ad17-f94955d997a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### dim_cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88496422-0211-4746-b109-b83cdbc16429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "  cliente_id as id,\n",
    "  \n",
    "  -- Dados pessoais\n",
    "  nome,\n",
    "  split(nome, ' ')[0] AS primeiro_nome,\n",
    "  telefone,\n",
    "  CASE \n",
    "    WHEN email LIKE '%@%.%' THEN lower(trim(email))\n",
    "    ELSE NULL \n",
    "  END AS email,\n",
    "  \n",
    "  -- Informações demográficas\n",
    "  data_nascimento,\n",
    "  -- Faixa etária usando cálculo alternativo universal\n",
    "  CASE \n",
    "    WHEN floor(months_between(current_date(), data_nascimento)/12) < 12 THEN 'Criança (<12)'\n",
    "    WHEN floor(months_between(current_date(), data_nascimento)/12) BETWEEN 12 AND 17 THEN 'Adolescente (12-17)'\n",
    "    WHEN floor(months_between(current_date(), data_nascimento)/12) BETWEEN 18 AND 24 THEN 'Jovem Adulto (18-24)'\n",
    "    WHEN floor(months_between(current_date(), data_nascimento)/12) BETWEEN 25 AND 34 THEN 'Adulto Jovem (25-34)'\n",
    "    WHEN floor(months_between(current_date(), data_nascimento)/12) BETWEEN 35 AND 44 THEN 'Adulto (35-44)'\n",
    "    WHEN floor(months_between(current_date(), data_nascimento)/12) BETWEEN 45 AND 59 THEN 'Meia Idade (45-59)'\n",
    "    ELSE 'Idoso (60+)'\n",
    "  END AS faixa_etaria,\n",
    "  \n",
    "  -- Calcula idade exata (usando months_between)\n",
    "  floor(months_between(current_date(), data_nascimento)/12) AS idade,\n",
    "  \n",
    "  -- Dia da semana de nascimento\n",
    "  date_format(data_nascimento, 'EEEE') AS dia_semana_nascimento,\n",
    "  \n",
    "  -- Estação do ano de nascimento\n",
    "  CASE \n",
    "    WHEN month(data_nascimento) BETWEEN 3 AND 5 THEN 'Primavera'\n",
    "    WHEN month(data_nascimento) BETWEEN 6 AND 8 THEN 'Verão'\n",
    "    WHEN month(data_nascimento) BETWEEN 9 AND 11 THEN 'Outono'\n",
    "    ELSE 'Inverno'\n",
    "  END AS estacao_nascimento,\n",
    "  \n",
    "  -- Dados de cadastro\n",
    "  date(data_cadastro) AS data_cadastro,\n",
    "  \n",
    "  -- Tempo como cliente em dias (alternativa universal)\n",
    "  datediff(current_date(), date(data_cadastro)) AS dias_como_cliente,\n",
    "  \n",
    "  -- Status\n",
    "  ativo,\n",
    "  \n",
    "  -- Segmentação por tempo de cadastro\n",
    "  CASE\n",
    "    WHEN datediff(current_date(), date(data_cadastro)) > 365 THEN 'Cliente Antigo'\n",
    "    WHEN datediff(current_date(), date(data_cadastro)) > 180 THEN 'Cliente Regular'\n",
    "    ELSE 'Cliente Novo'\n",
    "  END AS segmento_tempo,\n",
    "  \n",
    "  -- Metadados\n",
    "  input_file_name() AS origem_dados,\n",
    "  ingestion_time as data_carga,\n",
    "  deletion_time as data_exclusao\n",
    "FROM cliente\n",
    "\"\"\").createOrReplaceTempView(\"dim_cliente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb92df88-12e5-4de5-b3c5-d7b14deff6ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### dim_profissional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a519c6b9-83f9-4f16-8e00-434ed1f6f820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "      profissional_id as id,\n",
    "      nome,\n",
    "      telefone,\n",
    "      email,\n",
    "      especialidade,\n",
    "      data_admissao,\n",
    "      months_between(current_date(), data_admissao) AS tempo_empresa_meses,\n",
    "      ativo,\n",
    "      input_file_name() AS origem_dados,\n",
    "      ingestion_time as data_carga,\n",
    "      deletion_time as data_exclusao\n",
    "    FROM profissional\n",
    "\"\"\").createOrReplaceTempView(\"dim_profissional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef299e5-5acf-4460-9e2e-f4c71a28429e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### dim_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7de8cd4-bff2-4ad1-ba23-74ac69d2b326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "      servico_id as id,\n",
    "      nome,\n",
    "      descricao,\n",
    "      duracao_estimada,\n",
    "      preco,\n",
    "      CASE \n",
    "        WHEN lower(nome) LIKE '%barba%' THEN 'Barba'\n",
    "        WHEN lower(nome) LIKE '%corte%' THEN 'Corte'\n",
    "        WHEN lower(nome) LIKE '%pezinho%' THEN 'Pezinho'\n",
    "        WHEN lower(nome) LIKE '%sobrancelha%' THEN 'Sobrancelha'\n",
    "        ELSE 'Outros'\n",
    "      END AS categoria_servico,\n",
    "      ativo,\n",
    "      input_file_name() AS origem_dados,\n",
    "      ingestion_time as data_carga,\n",
    "      deletion_time as data_exclusao\n",
    "    FROM servico\n",
    "\"\"\").createOrReplaceTempView(\"dim_servico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d642a5-463d-4d44-83aa-04ad1b20bd99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### dim_tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9120353f-1047-4ade-93bf-809dffbcbe51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dim_tempo = spark.sql(\"\"\"\n",
    "    WITH dates AS (\n",
    "      SELECT explode(sequence(\n",
    "        to_date('2020-01-01'), \n",
    "        to_date('2030-12-31'), \n",
    "        interval 1 day\n",
    "      )) AS data_completa\n",
    "    )\n",
    "    SELECT \n",
    "      data_completa,\n",
    "      day(data_completa) AS dia,\n",
    "      month(data_completa) AS mes,\n",
    "      year(data_completa) AS ano,\n",
    "      quarter(data_completa) AS trimestre,\n",
    "      weekofyear(data_completa) AS semana_ano,\n",
    "      dayofweek(data_completa) AS dia_semana_numero,\n",
    "      date_format(data_completa, 'EEEE') AS nome_dia_semana,\n",
    "      (dayofweek(data_completa) IN (1, 7) OR month(data_completa) = 12 AND day(data_completa) = 25) AS feriado,\n",
    "      dayofweek(data_completa) IN (1, 7) AS fim_de_semana\n",
    "    FROM dates\n",
    "\"\"\").createOrReplaceTempView(\"dim_tempo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48adda43-2d1f-4cfd-b8c2-1d13686abaa3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## dim_promocoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676beea-cdcc-46f3-a6ff-fb58e8af68eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1. Quantificação e Listagem de Serviços Inclusos**  \n",
    "- **`qtd_servicos_inclusos`**: Conta quantos serviços estão associados a cada promoção.  \n",
    "- **`servicos_associados`**: Lista os nomes dos serviços em uma única string (ex: *\"Corte, Barba, Sobrancelha\"*).  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Análise Temporal das Promoções**  \n",
    "- **`duracao_dias_promocao`**: Calcula quantos dias a promoção ficou ativa.  \n",
    "- **`dias_desde_inicio`**: Dias passados desde o início da promoção.  \n",
    "- **`status_temporal`**: Classifica promoções em **\"Ativa\"**, **\"Programada\"** ou **\"Encerrada\"**.  \n",
    "- **`mes_inicio`** e **`mes_fim`**: Nomes dos meses de início e término.  \n",
    "- **`trimestre_promocao`**: Identifica se a promoção ocorreu em **Q1, Q2, Q3, Q4** ou se foi **multi-trimestral**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. Categorização de Descontos e Eventos**  \n",
    "- **`categoria_desconto`**: Classifica descontos como **Alto (≥30%)**, **Médio (15-29%)** ou **Baixo (<15%)**.  \n",
    "- **`tipo_evento`**: Identifica promoções sazonais (ex: *\"Natalina\"*, *\"Black Friday\"*) ou regulares.  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. Metadados e Rastreabilidade**  \n",
    "- **`origem_dados`**: Registra a fonte dos dados (arquivo Parquet original).  \n",
    "- **`data_carga`**: Data de ingestão dos dados para controle de atualizações.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c94a35-a92b-428d-89be-127d058cb893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH promocoes AS (\n",
    "    SELECT \n",
    "        promocao_id as id,\n",
    "        nome,\n",
    "        descricao,\n",
    "        desconto_percentual,\n",
    "        data_inicio,\n",
    "        data_fim,\n",
    "        ativo,\n",
    "        deletion_time as data_exclusao,\n",
    "        ingestion_time,\n",
    "        input_file_name() AS origem_dados\n",
    "    FROM promocao\n",
    "),\n",
    "servicos_por_promocao AS (\n",
    "    SELECT \n",
    "        sp.promocao_id,\n",
    "        COUNT(sp.servico_id) AS qtd_servicos,\n",
    "        COLLECT_LIST(s.nome) AS lista_servicos\n",
    "    FROM servico_promocao sp\n",
    "    LEFT JOIN servico s ON sp.servico_id = s.servico_id\n",
    "    GROUP BY sp.promocao_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    p.*,\n",
    "    COALESCE(sp.qtd_servicos, 0) AS qtd_servicos_inclusos,\n",
    "    CONCAT_WS(', ', sp.lista_servicos) AS servicos_associados,\n",
    "    datediff(p.data_fim, p.data_inicio) AS duracao_dias_promocao,\n",
    "    datediff(current_date(), p.data_inicio) AS dias_desde_inicio,\n",
    "    CASE \n",
    "        WHEN current_date() BETWEEN p.data_inicio AND p.data_fim THEN 'Ativa'\n",
    "        WHEN current_date() < p.data_inicio THEN 'Programada'\n",
    "        ELSE 'Encerrada'\n",
    "    END AS status_temporal,\n",
    "    CASE \n",
    "        WHEN p.desconto_percentual >= 30 THEN 'Alto desconto'\n",
    "        WHEN p.desconto_percentual >= 15 THEN 'Médio desconto'\n",
    "        ELSE 'Baixo desconto'\n",
    "    END AS categoria_desconto,\n",
    "    date_format(p.data_inicio, 'MMMM') AS mes_inicio,\n",
    "    date_format(p.data_fim, 'MMMM') AS mes_fim,\n",
    "    CASE \n",
    "        WHEN date_format(p.data_inicio, 'Q') = '1' AND date_format(p.data_fim, 'Q') = '1' THEN 'Q1'\n",
    "        WHEN date_format(p.data_inicio, 'Q') = '2' AND date_format(p.data_fim, 'Q') = '2' THEN 'Q2'\n",
    "        WHEN date_format(p.data_inicio, 'Q') = '3' AND date_format(p.data_fim, 'Q') = '3' THEN 'Q3'\n",
    "        WHEN date_format(p.data_inicio, 'Q') = '4' AND date_format(p.data_fim, 'Q') = '4' THEN 'Q4'\n",
    "        ELSE 'Multi-trimestral'\n",
    "    END AS trimestre_promocao,\n",
    "    CASE \n",
    "        WHEN lower(p.nome) LIKE '%natal%' OR (month(p.data_inicio) = 12 AND month(p.data_fim) = 12) THEN 'Natalina'\n",
    "        WHEN lower(p.nome) LIKE '%dia dos pais%' OR (month(p.data_inicio) = 8 AND month(p.data_fim) = 8) THEN 'Dia dos Pais'\n",
    "        WHEN lower(p.nome) LIKE '%dia das mães%' OR (month(p.data_inicio) = 5 AND month(p.data_fim) = 5) THEN 'Dia das Mães'\n",
    "        WHEN lower(p.nome) LIKE '%black friday%' OR (month(p.data_inicio) = 11 AND month(p.data_fim) = 11) THEN 'Black Friday'\n",
    "        ELSE 'Regular'\n",
    "    END AS tipo_evento,\n",
    "    p.ingestion_time as data_carga\n",
    "FROM promocoes p\n",
    "LEFT JOIN servicos_por_promocao sp ON p.id = sp.promocao_id\n",
    "\"\"\").createOrReplaceTempView(\"dim_promocao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc749f17-1c0c-4bc2-bc19-d1d3dbbd204f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## fato_agendamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583caf74-3ff0-4b0a-a10c-c19208e33acb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1. Informações de Clientes, Profissionais e Serviços**\n",
    "- **`nome_cliente`**: Nome do cliente que fez o agendamento.\n",
    "- **`nome_profissional`**: Nome do barbeiro/profissional responsável.\n",
    "- **`nome_servico`**: Tipo de serviço agendado (corte, barba, etc.).\n",
    "- **`preco_original`**: Preço base do serviço.\n",
    "- **`duracao_estimada`**: Tempo previsto para o serviço.\n",
    "- **`especialidade`**: Especialização do profissional (ex.: \"Barbeiro\", \"Cabelereiro\").\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Dados de Promoções (Se Aplicável)**\n",
    "- **`nome_promocao`**: Nome da promoção vigente.\n",
    "- **`desconto_percentual`**: % de desconto aplicado (se houver promoção).\n",
    "- **Filtro inteligente**: Apenas promoções válidas no período do agendamento são consideradas.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Enriquecimento Temporal**\n",
    "- **`dia_semana_nome`**: Nome do dia da semana (ex.: \"Monday\").\n",
    "- **`dia_semana_numero`**: Número do dia (1=Dom, 2=Seg, ..., 7=Sáb).\n",
    "- **`hora_agendamento`**: Hora do agendamento (0-23).\n",
    "- **`periodo_dia`**: Classificação em **\"Manhã\" (0-11h)**, **\"Tarde\" (12-17h)**, **\"Noite\" (18-23h)**.\n",
    "- **`dias_antecedencia`**: Quantos dias antes o cliente agendou.\n",
    "- **`dias_para_agendamento`**: Quanto tempo falta para o agendamento (se futuro).\n",
    "- **`recencia_agendamento`**: Classificação temporal:\n",
    "  - **\"Últimos 30 dias\"** (recente)\n",
    "  - **\"31-90 dias\"** (intermediário)\n",
    "  - **\"Mais de 90 dias\"** (antigo)\n",
    "  - **\"Futuro\"** (agendamentos ainda não realizados).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44ace19a-d8d2-4ded-9649-c39907d02f16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH promocoes_ativas AS (\n",
    "      SELECT \n",
    "        sp.servico_id,\n",
    "        sp.promocao_id,\n",
    "        p.nome,\n",
    "        p.desconto_percentual,\n",
    "        p.data_inicio,\n",
    "        p.data_fim\n",
    "      FROM servico_promocao sp\n",
    "      JOIN promocao p ON sp.promocao_id = p.promocao_id\n",
    "      WHERE current_date() BETWEEN p.data_inicio AND p.data_fim\n",
    "    ),\n",
    "    agendamentos as (\n",
    "        select \n",
    "            agendamento_id as id, \n",
    "            cliente_id,\n",
    "            profissional_id,\n",
    "            servico_id,\n",
    "            data_hora,\n",
    "            duracao,\n",
    "            status,\n",
    "            observacoes,\n",
    "            data_criacao,\n",
    "            data_atualizacao,\n",
    "            ingestion_time,\n",
    "            deletion_time as data_exclusao,\n",
    "            input_file_name() AS origem_dados\n",
    "        from agendamento\n",
    "    )\n",
    "\n",
    "    SELECT \n",
    "      a.*,\n",
    "      c.nome AS nome_cliente,\n",
    "      p.nome AS nome_profissional,\n",
    "      s.nome AS nome_servico,\n",
    "      s.preco AS preco_original,\n",
    "      s.duracao_estimada,\n",
    "      p.especialidade,\n",
    "      pa.promocao_id,\n",
    "      pa.nome AS nome_promocao,\n",
    "      pa.desconto_percentual,\n",
    "\n",
    "      date_format(a.data_hora, 'EEEE') AS dia_semana_nome,\n",
    "      CASE date_format(a.data_hora, 'EEEE')\n",
    "        WHEN 'Sunday' THEN 1\n",
    "        WHEN 'Monday' THEN 2\n",
    "        WHEN 'Tuesday' THEN 3\n",
    "        WHEN 'Wednesday' THEN 4\n",
    "        WHEN 'Thursday' THEN 5\n",
    "        WHEN 'Friday' THEN 6\n",
    "        WHEN 'Saturday' THEN 7\n",
    "      END AS dia_semana_numero,\n",
    "\n",
    "      hour(a.data_hora) AS hora_agendamento,\n",
    "      CASE \n",
    "        WHEN hour(a.data_hora) < 12 THEN 'Manhã'\n",
    "        WHEN hour(a.data_hora) < 18 THEN 'Tarde'\n",
    "        ELSE 'Noite'\n",
    "      END AS periodo_dia,\n",
    "\n",
    "      datediff(date(a.data_hora), date(a.data_criacao)) AS dias_antecedencia,\n",
    "      datediff(date(a.data_hora), current_date()) AS dias_para_agendamento,\n",
    "\n",
    "      CASE \n",
    "        WHEN datediff(current_date(), date(a.data_hora)) BETWEEN 0 AND 30 THEN 'Últimos 30 dias'\n",
    "        WHEN datediff(current_date(), date(a.data_hora)) BETWEEN 31 AND 90 THEN '31-90 dias'\n",
    "        WHEN datediff(current_date(), date(a.data_hora)) > 90 THEN 'Mais de 90 dias'\n",
    "        ELSE 'Futuro'\n",
    "      END AS recencia_agendamento,\n",
    "      a.ingestion_time as data_carga,\n",
    "      True as ativo\n",
    "    FROM agendamentos as a\n",
    "    JOIN cliente c ON a.cliente_id = c.cliente_id\n",
    "    JOIN profissional p ON a.profissional_id = p.profissional_id\n",
    "    JOIN servico s ON a.servico_id = s.servico_id\n",
    "    LEFT JOIN promocoes_ativas pa ON a.servico_id = pa.servico_id \n",
    "      AND date(a.data_hora) BETWEEN pa.data_inicio AND pa.data_fim\n",
    "\"\"\").createOrReplaceTempView(\"fato_agendamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896de7ad-21d2-4a7c-9d5c-9ed07c520f01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## fato_pagamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d55472b-7e3e-41f8-b1c8-69061b3e7f1e",
   "metadata": {},
   "source": [
    "### 1. **Junção de Dados Relacionados**\n",
    "- Integração de **5 tabelas diferentes** (pagamento, agendamento, cliente, profissional, serviço)\n",
    "- Criação de uma visão unificada do processo de pagamento\n",
    "---\n",
    "### 2. **Cálculos Temporais**\n",
    "- `dias_entre_servico_pagamento`: Diferença em dias entre serviço e pagamento\n",
    "- `categoria_tempo_pagamento`: Classificação temporal do pagamento (antecipado, no dia, etc.)\n",
    "- `periodo_pagamento`: Período do dia (Manhã/Tarde/Noite)\n",
    "- `dia_semana_pagamento`: Dia da semana do pagamento\n",
    "---\n",
    "### 3. **Indicadores Financeiros**\n",
    "- `parcelamento_possivel`: Identifica se o pagamento pode ser parcelado (cartão + valor > 100)\n",
    "- `diferenca_valor`: Diferença entre valor pago e preço original do serviço\n",
    "---\n",
    "### 4. **Classificações de Status**\n",
    "- `status_consolidado`: Combina status de pagamento e agendamento para análise completa\n",
    "---\n",
    "### 5. **Metadados e Rastreabilidade**\n",
    "- `origem_dados`: Identificação da fonte dos dados (com `input_file_name()`)\n",
    "- `data_carga`: Timestamp de quando os dados foram ingeridos\n",
    "---\n",
    "### 6. **Melhorias de Qualidade**\n",
    "- Normalização de datas (`data_pagamento_date`)\n",
    "- Conversão de tipos para garantir cálculos precisos\n",
    "- Nomes descritivos para todos os campos derivados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9eccc80-4334-461c-8bd2-312e2383ed2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH pagamentos as (\n",
    "        select \n",
    "            pagamento_id as id,\n",
    "            agendamento_id,\n",
    "            valor_total,\n",
    "            forma_pagamento,\n",
    "            status,\n",
    "            data_pagamento,\n",
    "            observacoes,\n",
    "            deletion_time as data_exclusao,\n",
    "            input_file_name() AS origem_dados,\n",
    "            ingestion_time AS data_carga\n",
    "        from pagamento\n",
    "    )\n",
    "  SELECT \n",
    "        pg.*,\n",
    "        a.data_hora AS data_agendamento,\n",
    "        a.status AS status_agendamento,\n",
    "        a.duracao,\n",
    "        c.nome AS nome_cliente,\n",
    "        p.nome AS nome_profissional,\n",
    "        s.nome AS nome_servico,\n",
    "        s.preco AS preco_original,\n",
    "        date(pg.data_pagamento) AS data_pagamento_date,\n",
    "        \n",
    "        -- Correção: usando datediff (forma correta no Spark SQL)\n",
    "        datediff(date(pg.data_pagamento), date(a.data_hora)) AS dias_entre_servico_pagamento,\n",
    "        \n",
    "        CASE \n",
    "            WHEN pg.forma_pagamento = 'cartao_credito' AND pg.valor_total > 100 THEN TRUE\n",
    "            ELSE FALSE\n",
    "        END AS parcelamento_possivel,\n",
    "        \n",
    "        -- Atualizado para usar datediff\n",
    "        CASE \n",
    "            WHEN datediff(date(pg.data_pagamento), date(a.data_hora)) < 0 THEN 'Pago antecipado'\n",
    "            WHEN datediff(date(pg.data_pagamento), date(a.data_hora)) = 0 THEN 'Pago no dia'\n",
    "            WHEN datediff(date(pg.data_pagamento), date(a.data_hora)) BETWEEN 1 AND 7 THEN 'Pago em 1-7 dias'\n",
    "            ELSE 'Pago após 7 dias'\n",
    "        END AS categoria_tempo_pagamento,\n",
    "        \n",
    "        CASE \n",
    "            WHEN hour(pg.data_pagamento) < 12 THEN 'Manhã'\n",
    "            WHEN hour(pg.data_pagamento) < 18 THEN 'Tarde'\n",
    "            ELSE 'Noite'\n",
    "        END AS periodo_pagamento,\n",
    "        \n",
    "        date_format(pg.data_pagamento, 'EEEE') AS dia_semana_pagamento,\n",
    "        \n",
    "        CASE \n",
    "            WHEN pg.status = 'pago' AND a.status = 'concluido' THEN 'Completo'\n",
    "            WHEN pg.status = 'pendente' AND a.status = 'concluido' THEN 'Serviço concluído mas não pago'\n",
    "            WHEN pg.status = 'pago' AND a.status != 'concluido' THEN 'Pago mas serviço não concluído'\n",
    "            ELSE 'Outras situações'\n",
    "        END AS status_consolidado,       \n",
    "        True as ativo,\n",
    "        -- Novo campo calculado: diferença entre valor pago e preço original\n",
    "        (pg.valor_total - s.preco) AS diferenca_valor\n",
    "    FROM pagamentos pg\n",
    "    JOIN agendamento a ON pg.id = a.agendamento_id\n",
    "    JOIN cliente c ON a.cliente_id = c.cliente_id\n",
    "    JOIN profissional p ON a.profissional_id = p.profissional_id\n",
    "    JOIN servico s ON a.servico_id = s.servico_id\n",
    "\"\"\").createOrReplaceTempView(\"fato_pagamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63467379-361a-49b5-8ebd-87e213e29c36",
   "metadata": {},
   "source": [
    "## Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f821cb1-ffcd-4c26-8f9c-2635671075ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delta_table_exists(spark, path):\n",
    "    \"\"\"\n",
    "    Verifica se uma tabela Delta existe no caminho especificado\n",
    "    \n",
    "    Args:\n",
    "        spark: SparkSession\n",
    "        path: Caminho para a tabela Delta (pode ser caminho S3, HDFS ou local)\n",
    "        \n",
    "    Returns:\n",
    "        bool: True se a tabela existe, False caso contrário\n",
    "    \"\"\"\n",
    "    try:\n",
    "        DeltaTable.forPath(spark, path)\n",
    "        return True\n",
    "    except AnalysisException as e:\n",
    "        if 'is not a Delta table' in str(e) or 'Path does not exist' in str(e):\n",
    "            return False\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Captura outros possíveis erros\n",
    "        if 'does not exist' in str(e):\n",
    "            return False\n",
    "        raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5dc6c7-f906-463d-a21f-f986787bc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_with_delete_track(spark: SparkSession, delta_path: str, pk_column: str, ingestion_time_column: str = \"data_carga\", table_name: str = None):\n",
    "    delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "    target_df = delta_table.toDF()\n",
    "    \n",
    "    source_df= spark.sql(f\"select * from {t}\")\n",
    "    source_df.createOrReplaceTempView(\"source_data\")\n",
    "    target_df.createOrReplaceTempView(\"target_data\")\n",
    "    \n",
    "    \n",
    "    records_to_deactivate = spark.sql(f\"\"\"\n",
    "        SELECT t.{pk_column}\n",
    "        FROM target_data t\n",
    "        LEFT JOIN {table_name} s ON t.{pk_column} = s.{pk_column}\n",
    "        WHERE s.{pk_column} IS NULL AND t.ativo = true\n",
    "    \"\"\")\n",
    "\n",
    "    count_to_deactivate = records_to_deactivate.count()\n",
    "    print(f\"Registros a desativar: {count_to_deactivate}\")\n",
    "    records_to_deactivate.show(truncate=False)\n",
    "    ids_to_deactivate = records_to_deactivate.select(pk_column).rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    if ids_to_deactivate:\n",
    "        print(f\"Encontrados {len(ids_to_deactivate)} registros para desativar\")\n",
    "\n",
    "        delta_table.update(\n",
    "            condition=F.col(pk_column).isin(ids_to_deactivate) & (F.col(\"ativo\") == True),\n",
    "            set={\n",
    "                \"ativo\": F.lit(False),\n",
    "                \"data_exclusao\": F.current_timestamp(),\n",
    "                \"data_carga\": F.current_timestamp()\n",
    "            }\n",
    "        )\n",
    "        print(\"Registros desativados.\")\n",
    "    else:\n",
    "        print(\"Nenhum registro para desativar encontrado.\")\n",
    "    \n",
    "    # UPSERT\n",
    "    delta_table.alias(\"target\").merge(\n",
    "        source_df.alias(\"source\"),\n",
    "        f\"target.{pk_column} = source.{pk_column}\"\n",
    "    ).whenMatchedUpdate(\n",
    "        condition=f\"source.{ingestion_time_column} > target.{ingestion_time_column}\",\n",
    "        set={\n",
    "            col: f\"source.{col}\"\n",
    "            for col in source_df.columns\n",
    "            if col != pk_column and col in target_df.columns\n",
    "        }\n",
    "    ).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "    print(\"UPSERT concluído!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57cf3a08-0b72-4454-89d8-44a176e74044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabelas_silver = [\n",
    "    \"dim_cliente\",\n",
    "    \"dim_profissional\",\n",
    "    \"dim_servico\",\n",
    "    \"dim_tempo\",\n",
    "    \"fato_agendamento\",\n",
    "    \"fato_pagamento\",\n",
    "    \"dim_promocao\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7302446-9c96-4999-a9ff-63710d2a8c21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 7 - Inicando ingestão na bronze para a tabela de dim_cliente\n",
      "Registros a desativar: 0\n",
      "+---+\n",
      "|id |\n",
      "+---+\n",
      "+---+\n",
      "\n",
      "Nenhum registro para desativar encontrado.\n",
      "UPSERT concluído!\n",
      "\n",
      "2 / 7 - Inicando ingestão na bronze para a tabela de dim_profissional\n",
      "Registros a desativar: 0\n",
      "+---+\n",
      "|id |\n",
      "+---+\n",
      "+---+\n",
      "\n",
      "Nenhum registro para desativar encontrado.\n",
      "UPSERT concluído!\n",
      "\n",
      "3 / 7 - Inicando ingestão na bronze para a tabela de dim_servico\n",
      "Registros a desativar: 0\n",
      "+---+\n",
      "|id |\n",
      "+---+\n",
      "+---+\n",
      "\n",
      "Nenhum registro para desativar encontrado.\n",
      "UPSERT concluído!\n",
      "\n",
      "4 / 7 - Inicando ingestão na bronze para a tabela de dim_tempo\n",
      "5 / 7 - Inicando ingestão na bronze para a tabela de fato_agendamento\n",
      "Registros a desativar: 0\n",
      "+---+\n",
      "|id |\n",
      "+---+\n",
      "+---+\n",
      "\n",
      "Nenhum registro para desativar encontrado.\n",
      "UPSERT concluído!\n",
      "\n",
      "6 / 7 - Inicando ingestão na bronze para a tabela de fato_pagamento\n",
      "Registros a desativar: 0\n",
      "+---+\n",
      "|id |\n",
      "+---+\n",
      "+---+\n",
      "\n",
      "Nenhum registro para desativar encontrado.\n",
      "UPSERT concluído!\n",
      "\n",
      "7 / 7 - Inicando ingestão na bronze para a tabela de dim_promocao\n",
      "Registros a desativar: 0\n",
      "+---+\n",
      "|id |\n",
      "+---+\n",
      "+---+\n",
      "\n",
      "Nenhum registro para desativar encontrado.\n",
      "UPSERT concluído!\n",
      "\n",
      "CPU times: user 103 ms, sys: 62.7 ms, total: 166 ms\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "contador=0\n",
    "for t in tabelas_silver:\n",
    "    contador+=1\n",
    "    print(f\"{contador} / {len(tabelas_silver)} - Inicando ingestão na bronze para a tabela de {t}\")\n",
    "    if delta_table_exists(spark, f\"{silver}{t}\") and t != 'dim_tempo':\n",
    "        upsert_with_delete_track(\n",
    "            spark,\n",
    "            delta_path=f\"{silver}{t}/\",\n",
    "            pk_column='id',\n",
    "            ingestion_time_column=\"data_carga\",\n",
    "            table_name=t\n",
    "        )\n",
    "    else:\n",
    "        df_silver = spark.sql(f\"select * from {t}\")\n",
    "        df_silver.write.mode(\"overwrite\").format(\"delta\").save(f\"{silver}{t}/\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae3f657e-c51b-4352-b9a5-6e7273682816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_cliente\n",
      "+------+---+---+\n",
      "|tabela| id|qtd|\n",
      "+------+---+---+\n",
      "+------+---+---+\n",
      "\n",
      "dim_profissional\n",
      "+------+---+---+\n",
      "|tabela| id|qtd|\n",
      "+------+---+---+\n",
      "+------+---+---+\n",
      "\n",
      "dim_servico\n",
      "+------+---+---+\n",
      "|tabela| id|qtd|\n",
      "+------+---+---+\n",
      "+------+---+---+\n",
      "\n",
      "fato_agendamento\n",
      "+------+---+---+\n",
      "|tabela| id|qtd|\n",
      "+------+---+---+\n",
      "+------+---+---+\n",
      "\n",
      "fato_pagamento\n",
      "+------+---+---+\n",
      "|tabela| id|qtd|\n",
      "+------+---+---+\n",
      "+------+---+---+\n",
      "\n",
      "dim_promocao\n",
      "+------+---+---+\n",
      "|tabela| id|qtd|\n",
      "+------+---+---+\n",
      "+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#validação duplicidade\n",
    "for t in tabelas_silver:\n",
    "    if t != 'dim_tempo':\n",
    "        print(t)\n",
    "        spark.sql(f\"\"\"\n",
    "            select \n",
    "                '{t}' as tabela,\n",
    "                id,\n",
    "                count(1) as qtd\n",
    "            from {t}\n",
    "            group by 1,2\n",
    "            having count(1) > 1\n",
    "        \"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
